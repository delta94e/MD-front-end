# OpenAI Tech Screen â€” Deep Dive

> ğŸ“… 2026-02-14 Â· â± 22 phÃºt Ä‘á»c
>
> ChatGPT Playground System Design (RADIO Format),
> Model Selection, DB Schema, API Design,
> Real-time Updates, Concurrent Updates,
> Streaming Chat Interface, Typewriter Effect,
> Multiple Concurrent Requests
> Äá»™ khÃ³: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ | OpenAI Frontend Tech Screen

---

## Má»¥c Lá»¥c

| #   | Pháº§n                                    |
| --- | --------------------------------------- |
| 1   | Tá»•ng quan quy trÃ¬nh phá»ng váº¥n           |
| 2   | RADIO Format â€” System Design Framework  |
| 3   | ChatGPT Playground â€” High Level Design  |
| 4   | Tech Stack & DB Schema                  |
| 5   | API Design                              |
| 6   | Real-time Update Implementations        |
| 7   | Component Tree & Text Editor UI         |
| 8   | Concurrent Updates                      |
| 9   | Coding: Streaming Chat Interface        |
| 10  | Follow-up: Multiple Concurrent Requests |
| 11  | Follow-up: Typewriter Effect            |
| 12  | CSS: Match Exact Layout                 |
| 13  | TÃ³m táº¯t phá»ng váº¥n                       |

---

## Â§1. Tá»•ng quan quy trÃ¬nh phá»ng váº¥n

```
OPENAI TECH SCREEN â€” FORMAT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Loop: FRONTEND (cÃ³ thá»ƒ chá»n FE hoáº·c Full-Stack!)

  â‘  SYSTEM DESIGN:
  â†’ "Design a ChatGPT Playground"
  â†’ Internal tool cho team!
  â†’ Chá»n model, edit parameters, chat, save/share/load presets!
  â†’ Format: RADIO (Requirements, Architecture, Data, Interface, Optimizations!)
  â†’ Topics: high-level design, tech stack, DB schemas, API design,
    real-time updates, component tree, text editor, concurrent updates!

  â‘¡ CODING:
  â†’ Build ChatGPT interface: submit prompt â†’ display response!
  â†’ ÄÆ°á»£c cho Sáº´N function stream response (chunks!)
  â†’ Follow-ups:
    â€¢ Style chÃ­nh xÃ¡c theo video! (CSS!)
    â€¢ Handle MULTIPLE requests while another is in-progress!
    â€¢ Typewriter effect (hiá»‡n tá»«ng kÃ½ tá»±!)
```

---

## Â§2. RADIO Format â€” System Design Framework

```
RADIO â€” FRAMEWORK CHO FE SYSTEM DESIGN:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  R â€” REQUIREMENTS:
  â†’ Functional: user CAN DO gÃ¬?
  â†’ Non-functional: performance, scalability, security!
  â†’ Constraints: internal tool? Public? Scale?

  A â€” ARCHITECTURE:
  â†’ High-level components diagram!
  â†’ Client-server separation!
  â†’ Key modules & data flow!

  D â€” DATA MODEL:
  â†’ DB schemas!
  â†’ State management (client-side!)
  â†’ API contracts!

  I â€” INTERFACE (API + UI):
  â†’ API endpoints!
  â†’ Component tree!
  â†’ UI interactions!

  O â€” OPTIMIZATIONS:
  â†’ Performance!
  â†’ Scalability!
  â†’ Edge cases!
  â†’ Tradeoffs!
```

---

## Â§3. ChatGPT Playground â€” High Level Design

```
REQUIREMENTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  FUNCTIONAL:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â‘  SELECT MODEL: GPT-4, GPT-4-turbo, GPT-3.5, etc.    â”‚
  â”‚ â‘¡ EDIT PARAMETERS:                                    â”‚
  â”‚   â†’ temperature (0-2), max_tokens, top_p              â”‚
  â”‚   â†’ stop sequences, frequency_penalty, presence_penaltyâ”‚
  â”‚   â†’ system prompt!                                     â”‚
  â”‚ â‘¢ CHAT: send messages, receive streaming responses!    â”‚
  â”‚ â‘£ SAVE PRESET: lÆ°u config (model + params + system!)  â”‚
  â”‚ â‘¤ LOAD PRESET: load config Ä‘Ã£ lÆ°u!                    â”‚
  â”‚ â‘¥ SHARE PRESET: chia sáº» link cho teammates!           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  NON-FUNCTIONAL:
  â†’ Internal tool (KHÃ”NG public!) â†’ auth = internal SSO!
  â†’ Low latency: streaming response!
  â†’ Collaboration: share presets giá»¯a team members!
  â†’ Persistence: conversations & presets lÆ°u lÃ¢u dÃ i!
```

```
HIGH-LEVEL ARCHITECTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   React     â”‚ â†â”€â”€â†’ â”‚   Backend    â”‚ â†â”€â”€â†’ â”‚  Database  â”‚
  â”‚   Frontend  â”‚ SSE  â”‚   (Node.js)  â”‚      â”‚ (Postgres) â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚
        â”‚                      â–¼
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚  OpenAI API  â”‚
        â”‚               â”‚  (GPT-4...)  â”‚
        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Auth (SSO) â”‚   Internal tool â†’ corporate SSO!
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  DATA FLOW:
  1. User chá»n model + params + gÃµ message!
  2. Frontend â†’ POST /api/chat (vá»›i preset config!)
  3. Backend â†’ call OpenAI API (stream: true!)
  4. OpenAI streams chunks â†’ Backend â†’ SSE â†’ Frontend!
  5. Frontend hiá»ƒn thá»‹ tá»«ng chunk real-time!
```

---

## Â§4. Tech Stack & DB Schema

```
TECH STACK:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  FRONTEND:
  â†’ React + TypeScript!
  â†’ State: Zustand hoáº·c React Context (internal tool = Ä‘Æ¡n giáº£n!)
  â†’ Styling: CSS Modules hoáº·c Tailwind!
  â†’ Markdown rendering: react-markdown + remark-gfm!
  â†’ Code highlighting: Prism.js hoáº·c highlight.js!
  â†’ Text editor: CodeMirror hoáº·c Monaco (cho system prompt!)

  BACKEND:
  â†’ Node.js + Express (hoáº·c Next.js API routes!)
  â†’ OpenAI SDK (openai npm package!)
  â†’ SSE cho streaming!
  â†’ Auth: internal SSO middleware!

  DATABASE:
  â†’ PostgreSQL (relational â†’ presets, conversations, messages!)
  â†’ Redis: session cache, rate limiting!
```

```sql
-- â•â•â• DB SCHEMA â•â•â•

-- Users (tá»« SSO!):
CREATE TABLE users (
    id          UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email       VARCHAR(255) UNIQUE NOT NULL,
    name        VARCHAR(255) NOT NULL,
    created_at  TIMESTAMP DEFAULT NOW()
);

-- Presets (model + parameters!):
CREATE TABLE presets (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id         UUID REFERENCES users(id),
    name            VARCHAR(255) NOT NULL,
    model           VARCHAR(50) NOT NULL,       -- 'gpt-4', 'gpt-3.5-turbo'
    temperature     DECIMAL(3,2) DEFAULT 0.7,
    max_tokens      INTEGER DEFAULT 2048,
    top_p           DECIMAL(3,2) DEFAULT 1.0,
    frequency_penalty DECIMAL(3,2) DEFAULT 0,
    presence_penalty  DECIMAL(3,2) DEFAULT 0,
    system_prompt   TEXT,
    stop_sequences  TEXT[],                     -- Array of strings!
    is_shared       BOOLEAN DEFAULT FALSE,
    share_token     VARCHAR(64) UNIQUE,         -- URL token for sharing!
    created_at      TIMESTAMP DEFAULT NOW(),
    updated_at      TIMESTAMP DEFAULT NOW()
);

-- Conversations:
CREATE TABLE conversations (
    id          UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id     UUID REFERENCES users(id),
    preset_id   UUID REFERENCES presets(id),
    title       VARCHAR(255),                   -- Auto-generated from first message!
    created_at  TIMESTAMP DEFAULT NOW(),
    updated_at  TIMESTAMP DEFAULT NOW()
);

-- Messages:
CREATE TABLE messages (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,
    role            VARCHAR(20) NOT NULL,        -- 'user' | 'assistant' | 'system'
    content         TEXT NOT NULL,
    token_count     INTEGER,                     -- Track usage!
    model_used      VARCHAR(50),                 -- Which model responded
    latency_ms      INTEGER,                     -- Response time!
    created_at      TIMESTAMP DEFAULT NOW()
);

-- Indexes:
CREATE INDEX idx_presets_user ON presets(user_id);
CREATE INDEX idx_conversations_user ON conversations(user_id);
CREATE INDEX idx_messages_conversation ON messages(conversation_id);
CREATE INDEX idx_presets_share_token ON presets(share_token);
```

---

## Â§5. API Design

```
API ENDPOINTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”€â”€ CHAT â”€â”€
  POST   /api/chat
  â†’ Body: { conversationId, message, presetId }
  â†’ Response: SSE stream! (text/event-stream!)

  â”€â”€ CONVERSATIONS â”€â”€
  GET    /api/conversations              (list all!)
  GET    /api/conversations/:id          (get with messages!)
  POST   /api/conversations              (create new!)
  DELETE /api/conversations/:id          (delete!)

  â”€â”€ PRESETS â”€â”€
  GET    /api/presets                     (list user's presets!)
  GET    /api/presets/:id                 (get one!)
  POST   /api/presets                     (create!)
  PUT    /api/presets/:id                 (update!)
  DELETE /api/presets/:id                 (delete!)
  POST   /api/presets/:id/share           (generate share link!)
  GET    /api/shared/:token              (load shared preset!)

  â”€â”€ MODELS â”€â”€
  GET    /api/models                      (list available models!)
```

```typescript
// â•â•â• API TYPES â•â•â•

interface ChatRequest {
  conversationId: string;
  message: string;
  preset: {
    model: string;
    temperature: number;
    maxTokens: number;
    topP: number;
    systemPrompt?: string;
    stopSequences?: string[];
  };
}

// SSE response format:
// data: {"type":"chunk","content":"Hello"}
// data: {"type":"chunk","content":" world"}
// data: {"type":"done","tokenCount":15,"latencyMs":234}
// data: [DONE]

interface Preset {
  id: string;
  name: string;
  model: string;
  temperature: number;
  maxTokens: number;
  topP: number;
  frequencyPenalty: number;
  presencePenalty: number;
  systemPrompt?: string;
  stopSequences?: string[];
  isShared: boolean;
  shareUrl?: string;
}
```

```typescript
// â•â•â• BACKEND â€” SSE STREAMING ENDPOINT â•â•â•

app.post("/api/chat", async (req, res) => {
  const { conversationId, message, preset } = req.body;

  // SSE headers:
  res.setHeader("Content-Type", "text/event-stream");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");

  try {
    // Save user message:
    await db.messages.create({
      conversationId,
      role: "user",
      content: message,
    });

    // Call OpenAI API:
    const stream = await openai.chat.completions.create({
      model: preset.model,
      messages: [
        ...(preset.systemPrompt
          ? [{ role: "system", content: preset.systemPrompt }]
          : []),
        // Previous messages...
        { role: "user", content: message },
      ],
      temperature: preset.temperature,
      max_tokens: preset.maxTokens,
      stream: true,
    });

    let fullResponse = "";

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || "";
      if (content) {
        fullResponse += content;
        res.write(`data: ${JSON.stringify({ type: "chunk", content })}\n\n`);
      }
    }

    // Save assistant message:
    await db.messages.create({
      conversationId,
      role: "assistant",
      content: fullResponse,
      modelUsed: preset.model,
    });

    res.write(`data: ${JSON.stringify({ type: "done" })}\n\n`);
    res.write("data: [DONE]\n\n");
    res.end();
  } catch (error) {
    res.write(
      `data: ${JSON.stringify({ type: "error", message: error.message })}\n\n`,
    );
    res.end();
  }
});
```

---

## Â§6. Real-time Update Implementations

```
REAL-TIME UPDATES â€” SO SÃNH:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚              â”‚ SSE          â”‚ WebSocket    â”‚ Long Poll  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Direction    â”‚ Server â†’ FE  â”‚ Bidirectionalâ”‚ Server â†’ FEâ”‚
  â”‚ Protocol     â”‚ HTTP/1.1     â”‚ ws://        â”‚ HTTP       â”‚
  â”‚ Connection   â”‚ Persistent   â”‚ Persistent   â”‚ Repeated   â”‚
  â”‚ Reconnect    â”‚ Auto!        â”‚ Manual!      â”‚ N/A        â”‚
  â”‚ Binary data  â”‚ âŒ           â”‚ âœ…           â”‚ âŒ         â”‚
  â”‚ Complexity   â”‚ Tháº¥p!        â”‚ Trung bÃ¬nh!  â”‚ Tháº¥p!     â”‚
  â”‚ Scalability  â”‚ Tá»‘t!        â”‚ Tá»‘n memory!  â”‚ Tá»‘n conn!  â”‚
  â”‚ Use case     â”‚ STREAMING!   â”‚ Real-time    â”‚ Fallback!  â”‚
  â”‚              â”‚ ChatGPT!     â”‚ chat, games! â”‚            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  CHO CHATGPT PLAYGROUND:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â†’ SSE lÃ  BEST CHOICE! Táº¡i sao?                        â”‚
  â”‚                                                        â”‚
  â”‚ â‘  Unidirectional: chá»‰ cáº§n server â†’ client!            â”‚
  â”‚   (User gá»­i message qua POST, khÃ´ng cáº§n WS!)          â”‚
  â”‚                                                        â”‚
  â”‚ â‘¡ Auto-reconnect: EventSource tá»± reconnect!           â”‚
  â”‚                                                        â”‚
  â”‚ â‘¢ HTTP-based: dá»… deploy, CDN-friendly!                â”‚
  â”‚                                                        â”‚
  â”‚ â‘£ OpenAI API cÅ©ng dÃ¹ng SSE!                           â”‚
  â”‚   â†’ Backend proxy SSE tá»« OpenAI â†’ Frontend!            â”‚
  â”‚                                                        â”‚
  â”‚ WHEN to use WebSocket instead:                         â”‚
  â”‚ â†’ Real-time collaboration: 2+ users edit CÃ™NG LÃšC!    â”‚
  â”‚ â†’ Typing indicators, cursor positions!                 â”‚
  â”‚ â†’ High-frequency bidirectional updates!                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Â§7. Component Tree & Text Editor UI

```
COMPONENT TREE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  <App>
  â”œâ”€â”€ <AuthProvider>
  â”‚   â”œâ”€â”€ <Sidebar>
  â”‚   â”‚   â”œâ”€â”€ <ConversationList>
  â”‚   â”‚   â”‚   â””â”€â”€ <ConversationItem>  â† click to load!
  â”‚   â”‚   â”œâ”€â”€ <NewChatButton>
  â”‚   â”‚   â””â”€â”€ <PresetSelector>
  â”‚   â”‚       â”œâ”€â”€ <PresetDropdown>
  â”‚   â”‚       â””â”€â”€ <PresetActions>  (save/share/load!)
  â”‚   â”‚
  â”‚   â””â”€â”€ <MainPanel>
  â”‚       â”œâ”€â”€ <HeaderBar>
  â”‚       â”‚   â”œâ”€â”€ <ModelSelector>     â† dropdown GPT-4/3.5!
  â”‚       â”‚   â””â”€â”€ <ParameterPanel>
  â”‚       â”‚       â”œâ”€â”€ <SliderControl>  (temperature!)
  â”‚       â”‚       â”œâ”€â”€ <NumberInput>    (max_tokens!)
  â”‚       â”‚       â””â”€â”€ <TextArea>       (stop sequences!)
  â”‚       â”‚
  â”‚       â”œâ”€â”€ <ChatArea>
  â”‚       â”‚   â”œâ”€â”€ <SystemPromptEditor>  â† CodeMirror/Monaco!
  â”‚       â”‚   â”œâ”€â”€ <MessageList>
  â”‚       â”‚   â”‚   â”œâ”€â”€ <UserMessage>
  â”‚       â”‚   â”‚   â””â”€â”€ <AssistantMessage>
  â”‚       â”‚   â”‚       â”œâ”€â”€ <MarkdownRenderer>
  â”‚       â”‚   â”‚       â”œâ”€â”€ <CodeBlock>
  â”‚       â”‚   â”‚       â””â”€â”€ <StreamingCursor>  â† blinking cursor!
  â”‚       â”‚   â””â”€â”€ <ScrollToBottom>
  â”‚       â”‚
  â”‚       â””â”€â”€ <InputArea>
  â”‚           â”œâ”€â”€ <PromptTextarea>   â† auto-resize!
  â”‚           â”œâ”€â”€ <SendButton>
  â”‚           â””â”€â”€ <StopButton>       â† abort streaming!
  â”‚
  â””â”€â”€ <ToastProvider>
```

```
TEXT EDITOR UI (SYSTEM PROMPT):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â‘  CodeMirror 6:
  â†’ Lightweight, modular, extensible!
  â†’ Syntax highlighting cho prompt templates!
  â†’ Line numbers, search/replace!
  â†’ âœ… RECOMMENDED cho Playground!

  â‘¡ Monaco Editor:
  â†’ VS Code engine! Full-featured!
  â†’ Autocomplete, intellisense!
  â†’ âŒ Heavy (2MB+)! Overkill cho system prompt!

  â‘¢ Plain <textarea>:
  â†’ ÄÆ¡n giáº£n nháº¥t!
  â†’ Auto-resize: adjust height to content!
  â†’ âŒ KhÃ´ng syntax highlighting!
  â†’ âœ… OK cho internal tool MVP!
```

---

## Â§8. Concurrent Updates

```
CONCURRENT UPDATES â€” Váº¤N Äá»€:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Scenario: 2 users EDIT cÃ¹ng 1 preset!
  â†’ User A: thay Ä‘á»•i temperature = 0.9!
  â†’ User B: thay Ä‘á»•i model = "gpt-4"!
  â†’ Cáº£ hai SAVE cÃ¹ng lÃºc â†’ AI OVERWRITES AI?

  GIáº¢I PHÃP:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â‘  LAST WRITE WINS (Ä‘Æ¡n giáº£n nháº¥t!):                   â”‚
  â”‚ â†’ Ai save SAU = GHI ÄÃˆ!                              â”‚
  â”‚ â†’ âœ… OK cho internal tool (Ã­t conflict!)               â”‚
  â”‚ â†’ âŒ Máº¥t thay Ä‘á»•i cá»§a ngÆ°á»i khÃ¡c!                     â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ â‘¡ OPTIMISTIC LOCKING (versioning!):                   â”‚
  â”‚ â†’ Má»—i preset cÃ³ "version" number!                     â”‚
  â”‚ â†’ UPDATE ... WHERE version = X                         â”‚
  â”‚ â†’ Náº¿u version KHÃ”NG KHá»šP â†’ CONFLICT! ThÃ´ng bÃ¡o user! â”‚
  â”‚ â†’ âœ… RECOMMENDED cho Playground!                       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ â‘¢ CRDT / OT (collaborative editing!):                 â”‚
  â”‚ â†’ Conflict-free Replicated Data Types!                 â”‚
  â”‚ â†’ Operational Transform (Google Docs!)                 â”‚
  â”‚ â†’ âŒ QuÃ¡ phá»©c táº¡p cho Playground!                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```typescript
// â•â•â• OPTIMISTIC LOCKING â•â•â•

// DB: presets table cÃ³ column "version"!

async function updatePreset(
  id: string,
  updates: Partial<Preset>,
  version: number,
) {
  const result = await db.query(
    `
        UPDATE presets 
        SET model = $1, temperature = $2, ..., version = version + 1, updated_at = NOW()
        WHERE id = $3 AND version = $4
        RETURNING *
    `,
    [updates.model, updates.temperature, id, version],
  );

  if (result.rowCount === 0) {
    // VERSION MISMATCH! Ai Ä‘Ã³ Ä‘Ã£ edit!
    throw new ConflictError(
      "Preset was modified by another user. Please reload.",
    );
  }

  return result.rows[0];
}

// Frontend:
try {
  await savePreset(preset.id, changes, preset.version);
} catch (err) {
  if (err.status === 409) {
    // Show dialog: "Preset changed! Reload or overwrite?"
    showConflictDialog({
      onReload: () => refetchPreset(),
      onOverwrite: () => forceSavePreset(),
    });
  }
}
```

---

## Â§9. Coding: Streaming Chat Interface

```jsx
// â•â•â• CODING ROUND â€” STREAMING CHAT INTERFACE â•â•â•
// "Build a ChatGPT interface: submit prompt, display streaming response!"
// "They give you a function that streams response back in chunks!"

import { useState, useRef } from "react";

// HÃ m Ä‘Æ°á»£c cho Sáº´N (simulates OpenAI streaming!):
// function streamResponse(prompt: string, onChunk: (text: string) => void): Promise<void>

function ChatInterface() {
  const [prompt, setPrompt] = useState("");
  const [messages, setMessages] = useState([]);
  const [isStreaming, setIsStreaming] = useState(false);

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!prompt.trim() || isStreaming) return;

    const userMessage = { role: "user", content: prompt };
    const assistantMessage = { role: "assistant", content: "" };

    // ThÃªm cáº£ user + assistant (empty) message:
    setMessages((prev) => [...prev, userMessage, assistantMessage]);
    setPrompt("");
    setIsStreaming(true);

    try {
      await streamResponse(prompt, (chunk) => {
        // Cáº­p nháº­t message CUá»I CÃ™NG (assistant!):
        setMessages((prev) => {
          const updated = [...prev];
          const lastIdx = updated.length - 1;
          updated[lastIdx] = {
            ...updated[lastIdx],
            content: updated[lastIdx].content + chunk,
          };
          return updated;
        });
      });
    } catch (error) {
      setMessages((prev) => {
        const updated = [...prev];
        updated[updated.length - 1] = {
          role: "assistant",
          content: "Error: " + error.message,
          isError: true,
        };
        return updated;
      });
    } finally {
      setIsStreaming(false);
    }
  };

  return (
    <div className="chat-container">
      <div className="messages">
        {messages.map((msg, i) => (
          <div key={i} className={`message ${msg.role}`}>
            <div className="avatar">{msg.role === "user" ? "ğŸ‘¤" : "ğŸ¤–"}</div>
            <div className="content">
              {msg.content}
              {msg.role === "assistant" &&
                isStreaming &&
                i === messages.length - 1 && <span className="cursor">â–Œ</span>}
            </div>
          </div>
        ))}
      </div>

      <form onSubmit={handleSubmit} className="input-area">
        <textarea
          value={prompt}
          onChange={(e) => setPrompt(e.target.value)}
          onKeyDown={(e) => {
            if (e.key === "Enter" && !e.shiftKey) {
              e.preventDefault();
              handleSubmit(e);
            }
          }}
          placeholder="Send a message..."
          disabled={isStreaming}
        />
        <button type="submit" disabled={isStreaming || !prompt.trim()}>
          {isStreaming ? "..." : "Send"}
        </button>
      </form>
    </div>
  );
}
```

---

## Â§10. Follow-up: Multiple Concurrent Requests

```
Váº¤N Äá»€: MULTIPLE REQUESTS WHILE STREAMING:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  User gá»­i message 1 â†’ streaming response...
  User gá»­i message 2 TRONG KHI message 1 Ä‘ang stream!
  â†’ PHáº¢I handle Cáº¢ HAI! KhÃ´ng block!

  CÃCH TIáº¾P Cáº¬N:
  â†’ Má»—i message pair cÃ³ RIÃŠNG streaming state!
  â†’ DÃ¹ng MESSAGE ID Ä‘á»ƒ track!
  â†’ KHÃ”NG dÃ¹ng single isStreaming boolean!
```

```jsx
// â•â•â• MULTIPLE CONCURRENT REQUESTS â•â•â•

import { useState, useRef, useCallback } from "react";

function ChatConcurrent() {
  const [messages, setMessages] = useState([]);
  const [prompt, setPrompt] = useState("");
  const activeStreams = useRef(new Set()); // Track active streams!

  const handleSubmit = useCallback(
    async (e) => {
      e.preventDefault();
      if (!prompt.trim()) return;

      const userMsg = { id: Date.now(), role: "user", content: prompt };
      const assistantId = Date.now() + 1;
      const assistantMsg = {
        id: assistantId,
        role: "assistant",
        content: "",
        isStreaming: true,
      };

      setMessages((prev) => [...prev, userMsg, assistantMsg]);
      setPrompt("");

      // Track stream:
      activeStreams.current.add(assistantId);

      try {
        await streamResponse(prompt, (chunk) => {
          setMessages((prev) =>
            prev.map((msg) =>
              msg.id === assistantId
                ? { ...msg, content: msg.content + chunk }
                : msg,
            ),
          );
        });
      } catch (error) {
        setMessages((prev) =>
          prev.map((msg) =>
            msg.id === assistantId
              ? { ...msg, content: "Error: " + error.message, isError: true }
              : msg,
          ),
        );
      } finally {
        // Mark done:
        activeStreams.current.delete(assistantId);
        setMessages((prev) =>
          prev.map((msg) =>
            msg.id === assistantId ? { ...msg, isStreaming: false } : msg,
          ),
        );
      }
    },
    [prompt],
  );

  const isAnyStreaming = messages.some((m) => m.isStreaming);

  return (
    <div className="chat-container">
      <div className="messages">
        {messages.map((msg) => (
          <div key={msg.id} className={`message ${msg.role}`}>
            <div className="content">
              {msg.content}
              {msg.isStreaming && <span className="cursor">â–Œ</span>}
            </div>
          </div>
        ))}
      </div>

      <form onSubmit={handleSubmit}>
        <textarea
          value={prompt}
          onChange={(e) => setPrompt(e.target.value)}
          onKeyDown={(e) => {
            if (e.key === "Enter" && !e.shiftKey) {
              e.preventDefault();
              handleSubmit(e);
            }
          }}
          placeholder="Send a message..."
          // âš ï¸ KHÃ”NG disable! Cho phÃ©p gá»­i khi Ä‘ang stream!
        />
        <button type="submit" disabled={!prompt.trim()}>
          Send
        </button>
      </form>
    </div>
  );
}

// KEY DIFFERENCES:
// â‘  Má»—i message cÃ³ RIÃŠNG id + isStreaming!
// â‘¡ DÃ¹ng msg.id Ä‘á»ƒ update ÄÃšNG message!
// â‘¢ Input KHÃ”NG bá»‹ disable khi streaming!
// â‘£ activeStreams ref track táº¥t cáº£ streams!
// â‘¤ Nhiá»u streams cháº¡y SONG SONG!
```

---

## Â§11. Follow-up: Typewriter Effect

```
TYPEWRITER EFFECT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Streaming tráº£ vá» CHUNKS (VD: "Hello " + "world" + "!")
  NhÆ°ng muá»‘n hiá»‡n Tá»ªNG KÃ Tá»° má»™t â†’ smoother!

  CÃCH LÃ€M:
  â†’ Nháº­n chunk â†’ Ä‘áº©y vÃ o QUEUE!
  â†’ setInterval: láº¥y 1 kÃ½ tá»± tá»« queue â†’ hiá»ƒn thá»‹!
  â†’ Tá»‘c Ä‘á»™: 20-50ms / character!
```

```jsx
// â•â•â• TYPEWRITER EFFECT â€” IMPLEMENTATION â•â•â•

import { useState, useRef, useEffect, useCallback } from "react";

function useTypewriter(speed = 30) {
  const [displayText, setDisplayText] = useState("");
  const queueRef = useRef(""); // Buffer chá»©a text CHÆ¯A HIá»‚N THá»Š!
  const intervalRef = useRef(null);
  const isTypingRef = useRef(false);

  // ThÃªm text vÃ o queue:
  const enqueue = useCallback(
    (text) => {
      queueRef.current += text;

      // Báº¯t Ä‘áº§u typing náº¿u chÆ°a cháº¡y:
      if (!isTypingRef.current) {
        isTypingRef.current = true;

        intervalRef.current = setInterval(() => {
          if (queueRef.current.length === 0) {
            // Háº¿t queue â†’ dá»«ng!
            clearInterval(intervalRef.current);
            isTypingRef.current = false;
            return;
          }

          // Láº¥y 1 kÃ½ tá»± tá»« queue:
          const char = queueRef.current[0];
          queueRef.current = queueRef.current.slice(1);
          setDisplayText((prev) => prev + char);
        }, speed);
      }
    },
    [speed],
  );

  // Reset:
  const reset = useCallback(() => {
    queueRef.current = "";
    setDisplayText("");
    if (intervalRef.current) clearInterval(intervalRef.current);
    isTypingRef.current = false;
  }, []);

  // Cleanup:
  useEffect(() => {
    return () => {
      if (intervalRef.current) clearInterval(intervalRef.current);
    };
  }, []);

  return { displayText, enqueue, reset, isTyping: isTypingRef.current };
}

// â•â•â• Sá»¬ Dá»¤NG TRONG CHAT â•â•â•

function ChatWithTypewriter() {
  const [messages, setMessages] = useState([]);
  const [prompt, setPrompt] = useState("");
  const [streamingId, setStreamingId] = useState(null);
  const typewriter = useTypewriter(30); // 30ms/char

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!prompt.trim()) return;

    const userMsg = { id: Date.now(), role: "user", content: prompt };
    const assistantId = Date.now() + 1;
    setMessages((prev) => [...prev, userMsg]);
    setPrompt("");
    setStreamingId(assistantId);
    typewriter.reset();

    try {
      await streamResponse(prompt, (chunk) => {
        // Äáº©y chunk vÃ o typewriter queue:
        typewriter.enqueue(chunk);
      });
    } catch (error) {
      typewriter.enqueue("\n\nError: " + error.message);
    } finally {
      // Äá»£i typewriter hiá»ƒn thá»‹ háº¿t:
      const waitForTypewriter = () => {
        return new Promise((resolve) => {
          const check = setInterval(() => {
            if (typewriter.queueRef?.current?.length === 0) {
              clearInterval(check);
              resolve();
            }
          }, 100);
        });
      };

      // LÆ°u message hoÃ n chá»‰nh:
      setMessages((prev) => [
        ...prev,
        {
          id: assistantId,
          role: "assistant",
          content: typewriter.displayText,
        },
      ]);
      setStreamingId(null);
    }
  };

  return (
    <div className="chat-container">
      <div className="messages">
        {messages.map((msg) => (
          <div key={msg.id} className={`message ${msg.role}`}>
            {msg.content}
          </div>
        ))}
        {/* Currently typing message: */}
        {streamingId && (
          <div className="message assistant">
            {typewriter.displayText}
            <span className="cursor blink">â–Œ</span>
          </div>
        )}
      </div>

      <form onSubmit={handleSubmit}>
        <textarea
          value={prompt}
          onChange={(e) => setPrompt(e.target.value)}
          placeholder="Send a message..."
        />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

```
TYPEWRITER â€” ADVANCED OPTIONS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â‘  SPEED VARIATION (tá»± nhiÃªn hÆ¡n!):
  â†’ Má»—i kÃ½ tá»±: speed + random(0, speed/2)!
  â†’ Sau dáº¥u cháº¥m: delay thÃªm 200ms!
  â†’ â†’ Giá»‘ng ngÆ°á»i tháº­t typing!

  â‘¡ requestAnimationFrame (SMOOTH!):
  â†’ Thay vÃ¬ setInterval â†’ rAF!
  â†’ Sync vá»›i browser paint cycle!
  â†’ 60fps smooth!

  â‘¢ BATCH CHARACTERS:
  â†’ Thay vÃ¬ 1 char/tick â†’ 2-3 chars/tick!
  â†’ Nhanh hÆ¡n, Ã­t state updates hÆ¡n!
  â†’ VD: náº¿u queue > 100 chars â†’ batch 3 chars!
```

---

## Â§12. CSS: Match Exact Layout

```css
/* â•â•â• CSS â€” CHATGPT STYLE LAYOUT â•â•â• */

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: "SÃ¶hne", "Segoe UI", system-ui, sans-serif;
  background: #343541;
  color: #ececf1;
}

.chat-container {
  display: flex;
  flex-direction: column;
  height: 100vh;
  max-width: 768px;
  margin: 0 auto; /* CENTER! */
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 16px 0;
}

.message {
  display: flex;
  gap: 16px;
  padding: 16px 24px;
  max-width: 768px;
  margin: 0 auto;
  line-height: 1.6;
}

.message.user {
  background: transparent;
}

.message.assistant {
  background: #444654;
}

.avatar {
  width: 30px;
  height: 30px;
  border-radius: 4px;
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  font-size: 16px;
}

.message.user .avatar {
  background: #5436da;
}
.message.assistant .avatar {
  background: #19c37d;
}

.content {
  flex: 1;
  white-space: pre-wrap;
  word-break: break-word;
}

/* INPUT AREA â€” BOTTOM! */
.input-area {
  padding: 16px 24px 24px;
  max-width: 768px;
  width: 100%;
  margin: 0 auto;
}

.input-area form {
  position: relative;
  display: flex;
  align-items: flex-end;
  background: #40414f;
  border: 1px solid #565869;
  border-radius: 12px;
  padding: 8px 12px;
}

.input-area textarea {
  flex: 1;
  background: transparent;
  border: none;
  outline: none;
  color: #ececf1;
  font-size: 16px;
  resize: none;
  max-height: 200px;
  line-height: 1.5;
  font-family: inherit;
}

.input-area button {
  background: #19c37d;
  border: none;
  border-radius: 6px;
  padding: 6px 12px;
  color: white;
  cursor: pointer;
  margin-left: 8px;
  flex-shrink: 0;
}

.input-area button:disabled {
  background: #565869;
  cursor: not-allowed;
}

/* BLINKING CURSOR */
.cursor {
  display: inline;
  animation: blink 0.7s infinite;
}

@keyframes blink {
  0%,
  100% {
    opacity: 1;
  }
  50% {
    opacity: 0;
  }
}

/* SCROLLBAR */
.messages::-webkit-scrollbar {
  width: 8px;
}
.messages::-webkit-scrollbar-thumb {
  background: #565869;
  border-radius: 4px;
}
```

---

## Â§13. TÃ³m táº¯t phá»ng váº¥n

```
PHá»NG Váº¤N â€” TRáº¢ Lá»œI:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Q: "Design ChatGPT Playground?"
  A: RADIO format! React + Node + Postgres.
  SSE streaming (unidirectional, auto-reconnect!).
  Presets = model + params + system prompt, shareable via token.
  Optimistic locking cho concurrent edits!

  Q: "DB Schema?"
  A: users, presets (model, temp, max_tokens, share_token),
  conversations, messages (role, content, token_count).
  Indexes on user_id, conversation_id, share_token!

  Q: "Real-time updates?"
  A: SSE cho streaming (OpenAI cÅ©ng dÃ¹ng!).
  WebSocket náº¿u cáº§n bidirectional (collaboration).
  Tradeoff: SSE = simple + auto-reconnect, WS = complex + features!

  Q: "Streaming chat code?"
  A: streamResponse(prompt, onChunk callback).
  onChunk: append chunk vÃ o LAST message (functional setState!).
  Blinking cursor khi streaming!

  Q: "Multiple concurrent requests?"
  A: Má»—i message cÃ³ RIÃŠNG id + isStreaming.
  DÃ¹ng id Ä‘á»ƒ update ÄÃšNG message.
  Input KHÃ”NG disable khi streaming! Set() track active streams!

  Q: "Typewriter effect?"
  A: onChunk â†’ Ä‘áº©y vÃ o QUEUE.
  setInterval: láº¥y 1 char tá»« queue â†’ display.
  Speed variation + batch chars khi queue dÃ i!
```

---

### Checklist

- [ ] **RADIO format**: R(requirements) A(architecture) D(data) I(interface) O(optimizations)!
- [ ] **Architecture**: React + Node + Postgres + SSE; OpenAI API proxy qua backend!
- [ ] **DB Schema**: users, presets (share_token!), conversations, messages (role + content + tokens)!
- [ ] **API**: POST /chat (SSE stream!), CRUD presets, CRUD conversations, GET /shared/:token!
- [ ] **Real-time**: SSE = best cho streaming (unidirectional, auto-reconnect!); WS cho collaboration!
- [ ] **Component Tree**: Sidebar (conversations + presets) + MainPanel (model + params + chat + input)!
- [ ] **Text Editor**: CodeMirror 6 (lightweight) > Monaco (heavy) > textarea (simple)!
- [ ] **Concurrent Updates**: Optimistic locking (version column + WHERE version = X)!
- [ ] **Streaming Code**: streamResponse callback â†’ append chunk to last message; blinking cursor!
- [ ] **Multiple Requests**: Má»—i message riÃªng id + isStreaming; update báº±ng id; input khÃ´ng disable!
- [ ] **Typewriter**: Queue buffer + setInterval 30ms/char; speed variation; batch khi queue dÃ i!
- [ ] **CSS**: max-width 768px center, dark theme #343541, flex column, auto-resize textarea!

---

_Nguá»“n: Reddit â€” OpenAI Frontend tech screen experience_
_Cáº­p nháº­t láº§n cuá»‘i: ThÃ¡ng 2, 2026_
